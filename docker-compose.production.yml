version: '3.8'

networks:
  niged_network:
    driver: bridge
  db_network:
    driver: bridge
    internal: true

volumes:
  postgres_data:
    driver: local
  rabbitmq_data:
    driver: local
  static_volume:
    driver: local
  media_volume:
    driver: local
  redis_data:
    driver: local
  logs_volume:
    driver: local

services:
  db:
    image: postgres:15-alpine
    container_name: niged_postgres
    environment:
      POSTGRES_USER: ${DB_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: postgres
      POSTGRES_INITDB_ARGS: "--encoding=UTF-8"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init-db.sql:/docker-entrypoint-initdb.d/init-db.sql
      - ./backups:/backups
    networks:
      - db_network
    restart: always
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER} -d postgres"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  redis:
    image: redis:7-alpine
    container_name: niged_redis
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD:-redis_password}
    volumes:
      - redis_data:/data
    networks:
      - niged_network
    restart: always
    deploy:
      resources:
        limits:
          memory: 256M
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "3"

  rabbitmq:
    image: rabbitmq:3-management-alpine
    container_name: niged_rabbitmq
    environment:
      RABBITMQ_DEFAULT_USER: ${RABBITMQ_USER}
      RABBITMQ_DEFAULT_PASS: ${RABBITMQ_PASSWORD}
      RABBITMQ_DEFAULT_VHOST: niged_vhost
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq
      - ./rabbitmq/rabbitmq.conf:/etc/rabbitmq/rabbitmq.conf
    networks:
      - niged_network
    restart: always
    deploy:
      resources:
        limits:
          memory: 512M
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  core_service:
    build:
      context: ./core_service
      dockerfile: Dockerfile.production
    container_name: niged_core_service
    environment:
      - DEBUG=0
      - SECRET_KEY=${CORE_SECRET_KEY}
      - ALLOWED_HOSTS=${ALLOWED_HOSTS}
      - DB_NAME=core_service_db
      - DB_USER=${DB_USER}
      - DB_PASSWORD=${DB_PASSWORD}
      - DB_HOST=db
      - DB_PORT=5432
      - RABBITMQ_HOST=rabbitmq
      - RABBITMQ_PORT=5672
      - RABBITMQ_USER=${RABBITMQ_USER}
      - RABBITMQ_PASSWORD=${RABBITMQ_PASSWORD}
      - RABBITMQ_VHOST=niged_vhost
      - REDIS_URL=redis://:${REDIS_PASSWORD:-redis_password}@redis:6379/0
      - CORS_ALLOWED_ORIGINS=${CORS_ALLOWED_ORIGINS}
      - SENTRY_DSN=${SENTRY_DSN:-}
      - ENABLE_MONITORING=${ENABLE_MONITORING:-false}
    volumes:
      - static_volume:/app/static
      - media_volume:/app/media
      - logs_volume:/app/logs
    networks:
      - niged_network
      - db_network
    restart: always
    depends_on:
      db:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
      redis:
        condition: service_healthy
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G
    command: >
      sh -c "
      python manage.py collectstatic --noinput --clear &&
      python manage.py migrate --noinput &&
      gunicorn core_service.wsgi:application 
        --bind 0.0.0.0:8000 
        --workers ${GUNICORN_WORKERS:-4} 
        --threads ${GUNICORN_THREADS:-2}
        --timeout 120
        --max-requests 1000
        --max-requests-jitter 100
        --preload
        --access-logfile /app/logs/gunicorn-access.log
        --error-logfile /app/logs/gunicorn-error.log
        --log-level info
      "
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"

  notification_service:
    build:
      context: ./notification_service
      dockerfile: Dockerfile.production
    container_name: niged_notification_service
    environment:
      - DEBUG=0
      - SECRET_KEY=${NOTIFICATION_SECRET_KEY}
      - ALLOWED_HOSTS=${ALLOWED_HOSTS}
      - DB_NAME=notification_service_db
      - DB_USER=${DB_USER}
      - DB_PASSWORD=${DB_PASSWORD}
      - DB_HOST=db
      - DB_PORT=5432
      - RABBITMQ_HOST=rabbitmq
      - RABBITMQ_PORT=5672
      - RABBITMQ_USER=${RABBITMQ_USER}
      - RABBITMQ_PASSWORD=${RABBITMQ_PASSWORD}
      - RABBITMQ_VHOST=niged_vhost
      - REDIS_URL=redis://:${REDIS_PASSWORD:-redis_password}@redis:6379/1
      - EMAIL_HOST=${EMAIL_HOST}
      - EMAIL_PORT=${EMAIL_PORT}
      - EMAIL_USE_TLS=${EMAIL_USE_TLS}
      - EMAIL_HOST_USER=${EMAIL_HOST_USER}
      - EMAIL_HOST_PASSWORD=${EMAIL_HOST_PASSWORD}
    volumes:
      - logs_volume:/app/logs
    networks:
      - niged_network
      - db_network
    restart: always
    depends_on:
      db:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
      redis:
        condition: service_healthy
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M
    command: >
      sh -c "
      python manage.py migrate --noinput &&
      gunicorn notification_service.wsgi:application 
        --bind 0.0.0.0:8001 
        --workers 2 
        --threads 2
        --timeout 120
        --max-requests 1000
        --access-logfile /app/logs/gunicorn-access.log
        --error-logfile /app/logs/gunicorn-error.log
        --log-level info
      "
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/health/"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"

  user_management_service:
    build:
      context: ./user_management_service
      dockerfile: Dockerfile.production
    container_name: niged_user_management_service
    environment:
      - DEBUG=0
      - SECRET_KEY=${USER_MANAGEMENT_SECRET_KEY}
      - ALLOWED_HOSTS=${ALLOWED_HOSTS}
      - DB_NAME=user_management_db
      - DB_USER=${DB_USER}
      - DB_PASSWORD=${DB_PASSWORD}
      - DB_HOST=db
      - DB_PORT=5432
      - REDIS_URL=redis://:${REDIS_PASSWORD:-redis_password}@redis:6379/2
      - EMAIL_HOST=${EMAIL_HOST}
      - EMAIL_PORT=${EMAIL_PORT}
      - EMAIL_USE_TLS=${EMAIL_USE_TLS}
      - EMAIL_HOST_USER=${EMAIL_HOST_USER}
      - EMAIL_HOST_PASSWORD=${EMAIL_HOST_PASSWORD}
      - JWT_SECRET_KEY=${JWT_SECRET_KEY}
      - JWT_ACCESS_TOKEN_LIFETIME=${JWT_ACCESS_TOKEN_LIFETIME}
      - JWT_REFRESH_TOKEN_LIFETIME=${JWT_REFRESH_TOKEN_LIFETIME}
      - CORS_ALLOWED_ORIGINS=${CORS_ALLOWED_ORIGINS}
    volumes:
      - logs_volume:/app/logs
    networks:
      - niged_network
      - db_network
    restart: always
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M
    command: >
      sh -c "
      python manage.py migrate --noinput &&
      gunicorn user_management.wsgi:application 
        --bind 0.0.0.0:8002 
        --workers 2 
        --threads 2
        --timeout 120
        --max-requests 1000
        --access-logfile /app/logs/gunicorn-access.log
        --error-logfile /app/logs/gunicorn-error.log
        --log-level info
      "
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8002/health/"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"

  nginx:
    build:
      context: ./nginx
      dockerfile: Dockerfile.production
    container_name: niged_nginx
    volumes:
      - static_volume:/static:ro
      - media_volume:/media:ro
      - ./ssl:/etc/nginx/ssl:ro
      - ./nginx/nginx.production.conf:/etc/nginx/nginx.conf:ro
      - logs_volume:/var/log/nginx
    ports:
      - "80:80"
      - "443:443"
    networks:
      - niged_network
    restart: always
    depends_on:
      - core_service
      - notification_service
      - user_management_service
    deploy:
      resources:
        limits:
          memory: 256M
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"

  # Backup service for automated database backups
  backup:
    image: postgres:15-alpine
    container_name: niged_backup
    environment:
      PGPASSWORD: ${POSTGRES_PASSWORD}
    volumes:
      - ./backups:/backups
      - ./scripts:/scripts
    networks:
      - db_network
    restart: "no"
    profiles:
      - backup
    command: >
      sh -c "
      echo '0 2 * * * /scripts/backup.sh' > /tmp/crontab &&
      crontab /tmp/crontab &&
      crond -f
      "

  # Monitoring with Prometheus (optional)
  prometheus:
    image: prom/prometheus:latest
    container_name: niged_prometheus
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
    ports:
      - "9090:9090"
    networks:
      - niged_network
    restart: always
    profiles:
      - monitoring
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'